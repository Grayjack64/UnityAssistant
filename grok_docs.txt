Chat

Text in, text out. Chat is the most popular feature on the xAI API, and can be used for anything from summarizing articles, generating creative writing, answering questions, providing customer support, to assisting with coding tasks.
Prerequisites

    xAI Account: You need an xAI account to access the API.
    API Key: Ensure that your API key has access to the chat endpoint and the chat model is enabled.

If you don't have these and are unsure of how to create one, follow the Hitchhiker's Guide to Grok.

You can create an API key on the xAI Console API Keys Page.

Set your API key in your environment:

bash

export XAI_API_KEY="your_api_key"

A Basic Chat Completions Example

You can also stream the response, which is covered in Streaming Response.

The user sends a request to the xAI API endpoint. The API processes this and returns a complete response.

import os
from openai import OpenAI

client = OpenAI(
    api_key="<YOUR_XAI_API_KEY_HERE>",
    base_url="https://api.x.ai/v1",
)

completion = client.chat.completions.create(
    model="grok-2-latest",
    messages=[
        {"role": "system", "content": "You are a PhD-level mathematician."},
        {"role": "user", "content": "What is 2 + 2?"},
    ],
)

print(completion.choices[0].message)

Response:

ChatCompletionMessage(
    content='2 + 2 equals 4.',
    refusal=None,
    role='assistant',
    audio=None,
    function_call=None,
    tool_calls=None
)

Conversations

The xAI API is stateless and does not process new request with the context of your previous request history.

However, you can provide previous chat generation prompts and results to a new chat generation request to let the model process your new request with the context in mind.

An example message:

json

{
  "role": "system",
  "content": [{ "type": "text", "text": "You are a helpful and funny assistant."}]
}
{
  "role": "user",
  "content": [{ "type": "text", "text": "Why don't eggs tell jokes?" }]
},
{
  "role": "assistant",
  "content": [{ "type": "text", "text": "They'd crack up!" }]
},
{
  "role": "user",
  "content": [{"type": "text", "text": "Can you explain the joke?"}],
}

By specifying roles, you can change how the the model ingest the content. The
system
role content should define, in an instructive tone, the way the model should respond to user request. The
user
role content is usually used for user request or data sent to the model. The
assistant
role content is usually either in the model's response, or when sent within the prompt, indicating the model's response as part of conversation history.

This strategy to send
assistant
role content can be used within function calling, in which the model response will invoke a tool call, the user's program responds to the tool call and continues the conversation by appending tool call result to the message. For more details, check out our guide on Function Calling.
Message role order flexibility

Unlike some models from other providers, one of the unique aspects of xAI API is its flexibility with message roles:

    No Order Limitation: You can mix
    system
    ,
    user
    , or
    assistant
    roles in any sequence for your conversation context.

Example 1 - Multiple System Messages:

json

[
{"role": "system", "content": "..."},
{"role": "system", "content": "..."},
{"role": "user", "content": "..."},
{"role": "user", "content": "..."}
]

The model takes multiple system

Example 2 - User Messages First:

json

{"role": "user", "content": "..."},
{"role": "user", "content": "..."},
{"role": "system", "content": "..."}


Streaming Response

Streaming outputs is supported by all models with text output capability (Chat, Image Understanding, etc.). It is not supported by models with image output capability (Image Generation).

Streaming outputs uses Server-Sent Events (SSE) that let the server send back the delta of content in event streams.

Streaming responses are beneficial for providing real-time feedback, enhancing user interaction by allowing text to be displayed as it's generated.

To enable streaming, you must set
"stream": true
in your request:

import os
from openai import OpenAI

XAI_API_KEY = os.getenv("XAI_API_KEY")
client = OpenAI(
    api_key=XAI_API_KEY,
    base_url="https://api.x.ai/v1",
)

stream = client.chat.completions.create(
    model="grok-2-latest",
    messages=[
        {"role": "system", "content": "You are Grok, a chatbot inspired by the Hitchhikers Guide to the Galaxy."},
        {"role": "user", "content": "What is the meaning of life, the universe, and everything?"},
    ],
    stream=True  # Set streaming here
)

for chunk in stream:
    print(chunk.choices[0].delta.content, end="", flush=True)

You'll get the event streams like these:

bash

data: {"id":"<completion_id>","object":"chat.completion.chunk","created":<creation_time>,"model":"grok-2-latest","choices":[{"index":0,"delta":{"content":"Ah","role":"assistant"}}],"usage":{"prompt_tokens":41,"completion_tokens":1,"total_tokens":42,"prompt_tokens_details":{"text_tokens":41,"audio_tokens":0,"image_tokens":0,"cached_tokens":0}},"system_fingerprint":"fp_xxxxxxxxxx"}
data: {"id":"<completion_id>","object":"chat.completion.chunk","created":<creation_time>,"model":"grok-2-latest","choices":[{"index":0,"delta":{"content":",","role":"assistant"}}],"usage":{"prompt_tokens":41,"completion_tokens":2,"total_tokens":43,"prompt_tokens_details":{"text_tokens":41,"audio_tokens":0,"image_tokens":0,"cached_tokens":0}},"system_fingerprint":"fp_xxxxxxxxxx"}
data: [DONE]

It is recommended that you use a client SDK to parse the event stream.

Example streaming responses in Python/Javascript:

bash

Ah, the ultimate question! According to Douglas Adams, the answer is **42**. However, the trick lies in figuring out what the actual question is. If you're looking for a bit more context or a different perspective:

- **Philosophically**: The meaning of life might be to seek purpose, happiness, or to fulfill one's potential.
- **Biologically**: It could be about survival, reproduction, and passing on genes.
- **Existentially**: You create your own meaning through your experiences and choices.

But let's not forget, the journey to find this meaning might just be as important as the answer itself! Keep exploring, questioning, and enjoying the ride through the universe. And remember, don't panic!


Image Understanding

The vision model can receive both text and image inputs. You can pass images into the model in one of two ways: base64 encoded strings or web URLs.

Under the hood, image understanding shares the same API route and the same message body schema consisted of
system
/
user
/
assistant
messages. The difference is having image in the message content body instead of text.

As the knowledge in this guide is built upon understanding of the chat capability. It is suggested that you familiarize yourself with the chat capability before following this guide.
Prerequisites

    xAI Account: You need an xAI account to access the API.
    API Key: Ensure that your API key has access to the vision endpoint and a model supporting image input is enabled.

If you don't have these and are unsure of how to create one, follow the Hitchhiker's Guide to Grok.

Set your API key in your environment:

bash

export XAI_API_KEY="your_api_key"

Reminder on image understanding model general limitations

It might be easier to run into model limit with these models than chat models:

    Maximum image size:
    10MiB
    Maximum number of images: No limit
    Supported image file types:
    jpg/jpeg
    or
    png
    .
    Any image/text input order is accepted (e.g. text prompt can precede image prompt)

Parameters
Request Body

messages

array

required

A list of messages that make up the the chat conversation. Different models support different message types, such as image and text.

model

string

required

Model name for the model to use. Obtainable from https://console.x.ai/team/default/models or https://docs.x.ai/docs/models.
Constructing the Message Body - Difference from Chat

The request message to image understanding is similar to chat. The main difference is that instead of text input:

json

[
    {
        "role": "user",
        "content": "What is in this image ?",
    }
]

We send in
content
as a list of objects:

json

[
    {
        "role": "user",
        "content": [
            {
                "type": "image_url",
                "image_url": {
                    "url": "data:image/jpeg;base64,<base64_image_string>",
                    "detail": "high",
                },
            },
            {
                "type": "text",
                "text": "What is in this image ?",
            },
        ],
    }
]

The
image_url.url
can also be the image's url on the Internet.

You can use the text prompt to ask questions about the image(s), or discuss topics with the image as context to the discussion, etc.
Web URL input

The model supports web URL as inputs for images. The API will fetch the image from the public URL and handle it as part of the chat. Integrating with URLs is as simple as:

import os
from openai import OpenAI

XAI_API_KEY = os.getenv("XAI_API_KEY")
image_url = (
    "https://science.nasa.gov/wp-content/uploads/2023/09/web-first-images-release.png"
)

client = OpenAI(
    api_key=XAI_API_KEY,
    base_url="https://api.x.ai/v1",
)

messages = [
    {
        "role": "user",
        "content": [
            {
                "type": "image_url",
                "image_url": {
                    "url": image_url,
                    "detail": "high",
                },
            },
            {
                "type": "text",
                "text": "What's in this image?",
            },
        ],
    },
]

completion = client.chat.completions.create(
    model="grok-2-vision-latest",
    messages=messages,
    temperature=0.01,
)

print(completion.choices[0].message.content)

Base64 string input

You will need to pass in base64 encoded image directly in the request, in the user messages.

Here is an example of how you can load a local image, encode it in Base64 and use it as part of your conversation:

import os
from openai import OpenAI
import os
import base64

XAI_API_KEY = os.getenv("XAI_API_KEY")
image_path = "..."

client = OpenAI(
    api_key=XAI_API_KEY,
    base_url="https://api.x.ai/v1",
)

def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        encoded_string = base64.b64encode(image_file.read()).decode("utf-8")
    return encoded_string

# Getting the base64 string
base64_image = encode_image(image_path)

messages = [
    {
        "role": "user",
        "content": [
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{base64_image}",
                    "detail": "high",
                },
            },
            {
                "type": "text",
                "text": "What's in this image?",
            },
        ],
    },
]

completion = client.chat.completions.create(
    model="grok-2-vision-latest",
    messages=messages,
    temperature=0.01,
)

print(completion.choices[0].message.content)

Multiple images input

You can send multiple images in the prompt, for example:

messages = [
    {
        "role": "user",
        "content": [
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{base64_image1}",
                    "detail": "high"
                }
            },
            {
                "type": "text",
                "text": "What are in these images?"
            },
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{base64_image2}",
                    "detail": "high",
                }
            }
        ],
    },
]

The image prompts can interleave with text prompts in any order.
Image token usage

The prompt image token usage is provided in the API response. Each image will be automatically broken down into tiles of 448x448 pixels, and each tile will consume 256 tokens. The final generation will include an extra tile, so each image would consume
(# of tiles + 1) * 256
tokens. There is a maximum limit of 6 tiles, so your input would consume less than 1,792 tokens per image.

python

# Stream response
print(next(stream).usage.prompt_tokens_details.image_tokens)

# Non-stream response
print(response.usage.prompt_tokens_details.image_tokens)


Image Generations

Some of the models can provide image generation capabilities. You can provide some descriptions of the image you would like to generate, and let the model generate one or multiple pictures in the output.

If you're used to interacting with the chat/image-understanding models, the image generation is a bit different from them. You only need to send a prompt text in the request, instead of a list of messages with system/user/assistant roles. When you sent the prompt for image generation, your prompt will be revised by a chat model, and then sent to the image generation model.
Parameters

    n
    : Number of image(s) to generate (1-10, default to 1)
    response_format
    :
    "url"
    or
    "b64_json"
    . If
    "url"
    is specified, the response will return a url to the image(s) in
    data[index].url
    ; if "b64_json" is specified, the response will return the image(s) in base64 encoded format in
    data[index].b64_json
    .

    Note:
    quality
    ,
    size
    or
    style
    are not supported by xAI API at the moment.

Request Body

prompt

string

required

Prompt for image generation.
Generate image

The image generation is offered at a different endpoint
https://api.x.ai/v1/images/generations
from the chat and image-understanding models that share
https://api.x.ai/v1/chat/completions
. The endpoint is compatible with OpenAI SDK (but not with Anthropic SDK), so you can keep using the same
base_url
of
https://api.x.ai/v1
.

You can set
"model": "grok-2-image"
in the request body to use the model. The generated image will be in
jpg
format.

import os

from openai import OpenAI

XAI_API_KEY = os.getenv("XAI_API_KEY")
client = OpenAI(base_url="https://api.x.ai/v1", api_key=XAI_API_KEY)

response = client.images.generate(
  model="grok-2-image",
  prompt="A cat in a tree"
)

print(response.data[0].url)

The Python and JavaScript examples will print out url of the image on xAI managed storage.

This is an example image generated from the above prompt:
A cat in a tree
Base 64 JSON Output

Instead of getting an image url by default, you can choose to get a base64 encoded image instead. To do so, you need to specify the
response_format
parameter to
"b64_json"
.

import os

from openai import OpenAI

XAI_API_KEY = os.getenv("XAI_API_KEY")
client = OpenAI(base_url="https://api.x.ai/v1", api_key=XAI_API_KEY)

response = client.images.generate(
  model="grok-2-image",
  prompt="A cat in a tree",
  response_format="b64_json"
)

print(response.data[0].b64_json)

You will get a
b64_json
field instead of
url
in the response image object.
Generating multiple images

You can generate up to 10 images in one request by adding a parameter
n
in your request body. For example, to generate four images:

import os

from openai import OpenAI

XAI_API_KEY = os.getenv("XAI_API_KEY")
client = OpenAI(base_url="https://api.x.ai/v1", api_key=XAI_API_KEY)

response = client.images.generate(
  model="grok-2-image",
  prompt="A cat in a tree"
  n=4
)
for image in response.data:
  print(image.url)

Revised prompt

If you inspect the response object, you can see something similar to this:

json

{
    "data": [
        {
            "b64_json": "data:image/png;base64,...",
            "revised_prompt": "..."
        }
    ]
}

Before sending the prompt to the image generation model, the prompt will be revised by a chat model. The revised prompt from chat model will be used by image generation model to create the image, and returned in
revised_prompt
to the user.

To see the revised prompt with OpenAI SDK:

# ... Steps to make image generation request

print(response.data[0].revised_prompt)

For example:
Input/Output	Example
prompt (in request body)	A cat in a tree
revised_prompt (in response body)	3D render of a gray cat with green eyes perched on a thick branch of a leafy tree, set in a suburban backyard during the day. The cat's fur is slightly ruffled by a gentle breeze, and it is looking directly at the viewer. The background features a sunny sky with a few clouds and other trees, creating a natural and serene environment. The scene is focused on the cat, with no distracting foreground elements, ensuring the cat remains the central subject of the image.